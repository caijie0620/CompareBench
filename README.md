# CompareBench

CompareBench is a benchmark for evaluating **visual comparison reasoning** in vision-language models (VLMs), covering four tasks: quantity, temporal, geometric, and spatial. It is derived from two auxiliary datasets:

- [TallyBench (2,000 counting images with QA)](https://huggingface.co/datasets/qiuzhangTiTi/TallyBench)  
- [HistCaps (515 historical images with bilingual captions)](https://huggingface.co/datasets/qiuzhangTiTi/HistCaps)  

The benchmark dataset is available here:  
- [CompareBench (1,000 QA pairs)](https://huggingface.co/datasets/qiuzhangTiTi/CompareBench)

---

ðŸ“Œ Paper: *CompareBench: A Benchmark for Visual Comparison Reasoning in Visionâ€“Language Models* (WACV 2026 submission)  
ðŸ“‚ Code, data, and prompts will be released in this repository.  
